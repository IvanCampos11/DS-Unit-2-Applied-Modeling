{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nCc3XZEyG3XV"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 2, Sprint 3, Module 3*\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Permutation & Boosting\n",
    "\n",
    "You will use your portfolio project dataset for all assignments this sprint.\n",
    "\n",
    "## Assignment\n",
    "\n",
    "Complete these tasks for your project, and document your work.\n",
    "\n",
    "- [ ] If you haven't completed assignment #1, please do so first.\n",
    "- [ ] Continue to clean and explore your data. Make exploratory visualizations.\n",
    "- [ ] Fit a model. Does it beat your baseline? \n",
    "- [ ] Try xgboost.\n",
    "- [ ] Get your model's permutation importances.\n",
    "\n",
    "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
    "\n",
    "But, if you aren't ready to try xgboost and permutation importances with your dataset today, that's okay. You can practice with another dataset instead. You may choose any dataset you've worked with previously.\n",
    "\n",
    "The data subdirectory includes the Titanic dataset for classification and the NYC apartments dataset for regression. You may want to choose one of these datasets, because example solutions will be available for each.\n",
    "\n",
    "\n",
    "## Reading\n",
    "\n",
    "Top recommendations in _**bold italic:**_\n",
    "\n",
    "#### Permutation Importances\n",
    "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
    "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
    "\n",
    "#### (Default) Feature Importances\n",
    "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
    "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
    "\n",
    "#### Gradient Boosting\n",
    "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
    "  - [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf), Chapter 8\n",
    "  - _**[Gradient Boosting Explained](https://www.gormanalysis.com/blog/gradient-boosting-explained/)**_ — Ben Gorman\n",
    "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html) — Alex Rogozhnikov\n",
    "  - [How to explain gradient boosting](https://explained.ai/gradient-boosting/) — Terence Parr & Jeremy Howard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://www.dropbox.com/s/6rc0ictd4uj9y27/high_diamond_ranked_10min.csv?dl=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       gameId  blueWins  blueWardsPlaced  blueWardsDestroyed  blueFirstBlood  \\\n0  4519157822         0               28                   2               1   \n1  4523371949         0               12                   1               0   \n2  4521474530         0               15                   0               0   \n3  4524384067         0               43                   1               0   \n4  4436033771         0               75                   4               0   \n\n   blueKills  blueDeaths  blueAssists  blueEliteMonsters  blueDragons  ...  \\\n0          9           6           11                  0            0  ...   \n1          5           5            5                  0            0  ...   \n2          7          11            4                  1            1  ...   \n3          4           5            5                  1            0  ...   \n4          6           6            6                  0            0  ...   \n\n   redTowersDestroyed  redTotalGold  redAvgLevel  redTotalExperience  \\\n0                   0         16567          6.8               17047   \n1                   1         17620          6.8               17438   \n2                   0         17285          6.8               17254   \n3                   0         16478          7.0               17961   \n4                   0         17404          7.0               18313   \n\n   redTotalMinionsKilled  redTotalJungleMinionsKilled  redGoldDiff  \\\n0                    197                           55         -643   \n1                    240                           52         2908   \n2                    203                           28         1172   \n3                    235                           47         1321   \n4                    225                           67         1004   \n\n   redExperienceDiff  redCSPerMin  redGoldPerMin  \n0                  8         19.7         1656.7  \n1               1173         24.0         1762.0  \n2               1033         20.3         1728.5  \n3                  7         23.5         1647.8  \n4               -230         22.5         1740.4  \n\n[5 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gameId</th>\n      <th>blueWins</th>\n      <th>blueWardsPlaced</th>\n      <th>blueWardsDestroyed</th>\n      <th>blueFirstBlood</th>\n      <th>blueKills</th>\n      <th>blueDeaths</th>\n      <th>blueAssists</th>\n      <th>blueEliteMonsters</th>\n      <th>blueDragons</th>\n      <th>...</th>\n      <th>redTowersDestroyed</th>\n      <th>redTotalGold</th>\n      <th>redAvgLevel</th>\n      <th>redTotalExperience</th>\n      <th>redTotalMinionsKilled</th>\n      <th>redTotalJungleMinionsKilled</th>\n      <th>redGoldDiff</th>\n      <th>redExperienceDiff</th>\n      <th>redCSPerMin</th>\n      <th>redGoldPerMin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4519157822</td>\n      <td>0</td>\n      <td>28</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n      <td>6</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16567</td>\n      <td>6.8</td>\n      <td>17047</td>\n      <td>197</td>\n      <td>55</td>\n      <td>-643</td>\n      <td>8</td>\n      <td>19.7</td>\n      <td>1656.7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4523371949</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>17620</td>\n      <td>6.8</td>\n      <td>17438</td>\n      <td>240</td>\n      <td>52</td>\n      <td>2908</td>\n      <td>1173</td>\n      <td>24.0</td>\n      <td>1762.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4521474530</td>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>11</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>17285</td>\n      <td>6.8</td>\n      <td>17254</td>\n      <td>203</td>\n      <td>28</td>\n      <td>1172</td>\n      <td>1033</td>\n      <td>20.3</td>\n      <td>1728.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4524384067</td>\n      <td>0</td>\n      <td>43</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>16478</td>\n      <td>7.0</td>\n      <td>17961</td>\n      <td>235</td>\n      <td>47</td>\n      <td>1321</td>\n      <td>7</td>\n      <td>23.5</td>\n      <td>1647.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4436033771</td>\n      <td>0</td>\n      <td>75</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>17404</td>\n      <td>7.0</td>\n      <td>18313</td>\n      <td>225</td>\n      <td>67</td>\n      <td>1004</td>\n      <td>-230</td>\n      <td>22.5</td>\n      <td>1740.4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df\n",
    "test = df.drop('blueWins',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(train, train_size=0.80, test_size=0.20, stratify=df['blueWins'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'blueWins'\n",
    "train_features = train.drop(columns=[target])\n",
    "numeric_features = train_features.select_dtypes(include='number').columns.tolist()\n",
    "features = numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "X_val = val[features]\n",
    "y_val = val[target]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 12.6 s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('standardscaler',\n                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n                ('randomforestclassifier',\n                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                        class_weight=None, criterion='gini',\n                                        max_depth=12, max_features='auto',\n                                        max_leaf_nodes=None, max_samples=None,\n                                        min_impurity_decrease=0.0,\n                                        min_impurity_split=None,\n                                        min_samples_leaf=1, min_samples_split=6,\n                                        min_weight_fraction_leaf=0.0,\n                                        n_estimators=999, n_jobs=1,\n                                        oob_score=False, random_state=42,\n                                        verbose=0, warm_start=False))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier(\n",
    "        n_jobs=1,\n",
    "        random_state=42,\n",
    "        max_depth=12,\n",
    "        min_samples_split=6,\n",
    "        n_estimators=999\n",
    "    )\n",
    ")\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "training accuracy: 0.9082626850563077\nvalidation accuracy: 0.7155870445344129\n"
    }
   ],
   "source": [
    "print('training accuracy:', pipeline.score(X_train, y_train))\n",
    "print('validation accuracy:', pipeline.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}